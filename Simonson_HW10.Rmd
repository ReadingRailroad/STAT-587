---
title: "Simonson_HW10"
author: "Martin Simonson"
date: "April 10, 2019"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

# 1. Bear Weight

```{r, include = F}
library(ggplot2)
library(car)
library(gridExtra)
bear<-read.table("Data/bears.txt",header=T)
str(bear)
```


Animal ecologists wish to track the health of bear populations in the wild. By obtaining physical measurements of bears, researchers can gauge the effects of changes taking place in and around bear habitat (e.g., nearby housing and business development, recreational activities, introduction of non-native plant and animal species, severe storms, harsh winters, etc.). Researchers have studied bears by anesthetizing them in order to obtain vital measurements, such as age, gender, length, and width. A bear’s weight is another important variable that is quite difficult to obtain in the wild because most bears are heavy and difficult to lift. The scientific problem is to develop a method for predicting the weight of a bear, given other more easily obtained measurements. A good method might alleviate the need to weigh bears in the wild and greatly simplify the data collection process.

In one detailed study, researchers were able to obtain weight measurements along with several other variables for each of 48 bears. The file _bears.txt_ contains the data for 48 bears. There is one row for each bear that was anesthetized and measured carefully using a tape measure and scale. There is one column for each variable in the data set. The variables (from left to right) are:

- length: length of body (in inches)
- sex: male or female
- weight: weight (in pounds)
- chest: chest circumference (in inches)
- headlen: length of head (in inches)
- headwid: width of head (in inches)
- month: month of capture
- neck: neck circumference (in inches)

## A)

Construct a scatterplot matrix of all the variables in the data set. Include the graph obtained and comment on the relationships between Y and the explanatory variables. When possible, describe the strength, direction, and type of relationship.

- __Answer:__ We see that weight (Y) has a strong positive linear relationship with chest and neck circumference, and a weaker (but still positive and linear) relationship with body length, head width and head length. There appears to be no clear relationship between weight and either sex or month.

```{r, echo = F}
pairs(bear)
```

## B)

Estimate the parameters in the multiple regression model with weight as the response variable and chest, length, and neck as explanatory variables. Specifically, provide an estimate of the intercept, an estimate of the partial regression coefficient for each explanatory variable, and an estimate of the standard deviation of bear weights for any given values of the explanatory variables (i.e. $\hat{\sigma}$).

```{r, echo = F}
mod<-lm(weight~chest+length+neck, data = bear)
summary(mod)
#anova(mod)
```

- __Answer:__ The intercept is estimated to be -276.2881, the estimated partial regression coefficient for _chest_ is 8.8238, the estimated partial regression coefficient for _length_ is 0.3037, and the estimated partial regression coefficient for _neck_ is 6.1419, and the estimated standard deviation is sqrt(31.64), or 5.625. 

## C)

Conduct one test of the null hypothesis that says that the partial regression coefficients for chest, neck and length are all zero against the alternative that at least one coefficient is not. State the hypotheses, the test statistic, the degrees of freedom, p-value and conclusion.

- __Answer:__ We want to test $H_0: \beta_1 = \beta_2 = \beta_3$ vs. $H_A: H_0$ is false. We can see from the summary table in _B)_ that the F-statistic is 210.1 on 3 and 44 degrees of freedom with a p-value less than 0.0001, providing very strong evidence against the null and we can conclude that the predictor variable coefficients are not all equal to 0.


## D)

Provide an interpretation of the partial regression coefficient associated with the variable _chest_.

- __Answer:__ With other variables held constant, a 1-inch increase in _chest_ circumference will result in a mean increase in weight of 8.8238 lbs.

## E)

Compute a 95% confidence interval for the partial regression coefficient associated with the variable length. Is the partial regression coefficient associated with the variable length significantly different from zero? Explain how your confidence interval can be used to answer this question.

```{r}
confint(mod)
```

- __Answer:__ The 95% confidence interval for the partial regression coefficient for _length_ is between -1.595 and 2.202. Therefore, this estimated coefficient is not signifciantly different from 0 because the interval for the estimate of the coefficient overlaps 0.

# 2. Bear Weight, revisited

Using the same model as in problem 1 (multiple linear regression of weight on _chest_, _length_, and _neck_):

## A)

What proportion of variation in bear weights is explained by the multiple regression of weight on _chest_, _length_, and _neck_?

- __Answer:__ The multiple $R^2$ from our model in _1.B)_ is 0.9348, which means that 93.48% of the overall variation in bear weights is explained by our model. 

## B)

Provide an estimate of the mean weight of a captured bear that is 60 inches long, with chest circumference of 35 inches, and neck circumference 24 inches.

```{r}
bearrr<-data.frame(length=60, chest = 35, neck = 24)
pred1<-predict(mod,newdata = bearrr,se.fit=T,interval="conf")
pred1$fit
```

- __Answer:__ Our predicted mean weight for a bear in with these measurements would be 198.1687 lbs. 

## C)

Provide a 95% confidence interval for the mean weight estimated in part (2b).

```{r}
pred1$fit
```

## D)

Provide a 95% prediction interval for the weight of the bear described in part (2b).

```{r}
pred2<-predict(mod,newdata = bearrr,se.fit=T,interval="predict")
pred2$fit
```

- __Answer:__ We are 95% confident that a bear that is 60 inches long, with a chest circumference of 35 inches, and a neck circumference of 24 inches will have a mean weight of between 131.36 and 264.98 pounds.

## E)

Examine the residual plot and the normal probability plot of the residuals from the fit of the multiple regression model with weight as the response variable and _chest_, _length_, and _neck_ as explanatory variables. Which of the assumptions of multiple linear regression is questionable based on these plots?

```{r, echo = F, out.height="200px"}
bear$resid<-resid(mod)
bear$fitted<-fitted(mod)
p1<-ggplot(bear,aes(x=fitted,y=resid))+geom_point()+theme_classic()+geom_hline(yintercept = 0)
p2<-ggplot(bear,aes(sample=resid))+stat_qq()+stat_qq_line()+theme_classic()
grid.arrange(p1,p2,ncol=2)
```

- __Answer:__ Both the normality assumption and homoskedasticity assumption are questionable because of curvature in the qq-plot and non-random scatter of data in the residuals vs. fitted plot, respectively.

## F)
### i)

How many categorical variables are provided in the data set? What are these variables?

- __Answer:__ There are two categorical variables, Sex and Month.

### ii)

How many dummy/indicator variables would you need to construct to incorporate the variable _month_ in a regression model? Define these variables here, using the Indicator coding used by the textbook. What level of this factor was the reference level?

- __Answer:__ One would need 7 dummy variables. The reference level would be April, compared to the rest of the months in lexicographic order.

Month                 | $Dummy_1$  | $Dummy_2$  | $Dummy_3$ | $Dummy_4$ | $Dummy_5$ | $Dummy_6$ | $Dummy_7$
--------------------- | -----------| -----------| ----------| ----------| ----------| ----------| ---------
April                 | 0          | 0          | 0         | 0         | 0         | 0         | 0
August                | 1          | 0          | 0         | 0         | 0         | 0         | 0
July                  | 0          | 1          | 0         | 0         | 0         | 0         | 0
June                  | 0          | 0          | 1         | 0         | 0         | 0         | 0
May                   | 0          | 0          | 0         | 1         | 0         | 0         | 0
November              | 0          | 0          | 0         | 0         | 1         | 0         | 0
October               | 0          | 0          | 0         | 0         | 0         | 1         | 0
September             | 0          | 0          | 0         | 0         | 0         | 0         | 1


## G)

Add the variable _sex_ to the model in question _1.B)_. Use R to fit the new model to the data. Interpret the estimated coefficient associated with the new _sex_ variable within the context of the data.

```{r}
mod<-lm(weight~chest+length+neck+sex, data = bear)
summary(mod)
```

- __Answer:__ The estimated coefficient for the effect of sex on bear weights is -5.0247, meaning that male bears will have an average of 5.0247 fewer pounds than female bears.

# 3. Mpi genotypes

```{r, include = F}
library(emmeans)
mpi<-read.table("Data/MPI.dat",header=T)
str(mpi)
```

The 1989 Nature article titled “Selection component analysis of the Mpi locus in the amphipod” presented a study of data collected on the amphipod crustacean _Platorchestia platensis_ on a beach near Stony Brook, Long Island, in April, 1987. The research group counted the number of eggs each female was carrying, freeze-dried them, weighed them, then used protein electrophoresis to determine the genotype at the locus for mannose-6-phosphate isomerase (Mpi). The data in _MPI.dat_ consist of four columns: the identification number of the individual, the weight (in mg), fertility (quantified by the number of eggs), and the genotype. The biological question is whether the Mpi genotypes differ in size-adjusted fecundity.

## A)

To answer the biological question, fit a parallel regression lines model to all genotypes. Write the estimated regression equation here, clearly explaining any notation or coding used.

- __Answer:__ Let $\hat{Y}$ denote the number of eggs and let $\hat{\beta_0}$ denote the estimated parallel lines regression intercept. Let $X$ denote the weight of the eggs (in mg) with estimated coefficient $\hat{\beta_1}$ (the coefficient for our baseline genotype _ff_), let $D_2$ denote the dummy variable for the genotype _fs_ (1 if _fs_, 0 otherwise) with estimated coefficient $\hat{\beta_2}$, and let $D_3$ denote the dummy variable for the genotype _ss_ (1 if _ss_, 0 otherwise) with estimated coefficient $\hat{\beta_3}$. Random error is denoted by $\epsilon$.

\[
\hat{Y} = \hat{\beta_0} + \hat{\beta_1}X + \hat{\beta_2}D_2 + \hat{\beta_3}D_3 + \epsilon
\]

```{r}
mod<-lm(Eggs~Weight + Genotype, data = mpi)
summary(mod)
```

\[
\hat{Y} = 14.12 + 1.444X_1 - 0.689D_2 - 0.374D_3 + \epsilon
\]

## B)

Using the parallel lines model, provide an interpretation of the relationship between weight and fertility. Make sure to include in your interpretation a number quantifying the magnitude of the relationship.

- __Answer:__ There is strong evidence that fertility is positively associated with the weight of the eggs (p-value <0.001) for the baseline genotype _ff_. For every 1 mg increase in weight, the mean increase in fertility is 1.444 eggs.

## C)

Using the parallel lines model, estimate the mean difference in fertility between genotypes _ff_ and _ss_, after adjusting for the effects of weight. Provide an s.e. of the estimate.

```{r}
mpi.emm<-emmeans(mod, ~ Genotype)
mpi.emm

contrast(mpi.emm, list("ff-ss"=c(1,0,-1)))
```

- __Answer:__ After controlling for weight, the mean difference in fertility between genotypes _ff_ and _ss_ is 0.374.

## D)

Using the parallel lines model, test the null hypothesis of no difference between genotypes _ff_ and _ss_, after adjusting for the effects of weight.

```{r}
contrast(mpi.emm, list("ff-ss"=c(1,0,-1)))
```

- __Answer:__ After controlling for weight, we observed a p-value of 0.7537 for the contrast between _ff_ and _ss_, therefore, there is no evidence that there is a true difference in fertility between genotypes. 

## E)

Using the parallel lines model, test the hypothesis of no differences in fertility between the three genotypes, after adjusting for the effects of weight. Write down the null and alternative hypothesis, give the name of the test used, the p-value, and a one sentence conclusion.

- __Answer:__ Let $\hat{\beta_1}$, $\hat{\beta_2}$, and $\hat{\beta_3}$ denote the regression coefficients for the effect of _ff_, _fs_, and _ss_ respectively. We want to test $H_0: \hat{\beta_1} = \hat{\beta_2} = \hat{\beta_3}$ vs. $H_A: H_0$ is false. Using the parallel lines model, accounting for weight, we yield the joint test result:

```{r}
joint_tests(mpi.emm)
```

With a p-value of 0.7816 we have no evidence to reject the null hypothesis that there is a true difference in egg numbers between the genotypes, after accounting for weight.


# 4. Mpi genotypes, revisited

Consider the same biological question as in Poblem 3, but now fit a regression model that allows the slope of the three regression lines (one for each genotype group) to vary.

## A)

a)	Write out the estimated regression equation, clearly explaining any notation or coding used.

- __Answer:__ Let $\hat{Y}$ denote the number of eggs and let $\hat{\beta_0}$ denote the estimated parallel lines regression intercept. Let $X$ denote the weight of the eggs (in mg) with estimated coefficient $\hat{\beta_1}$ (the coefficient for our baseline genotype _ff_), let $D_2$ denote the dummy variable for the genotype _fs_ (1 if _fs_, 0 otherwise) with estimated coefficient $\hat{\beta_2}$, and let $D_3$ denote the dummy variable for the genotype _ss_ (1 if _ss_, 0 otherwise) with estimated coefficient $\hat{\beta_3}$. Let $\hat{\beta_4}$ and $\hat{\beta_5}$ denote the interaction slope coefficients for genotypes _fs_ and _ss_, respectively. Random error is denoted by $\epsilon$.

\[
\hat{Y}=\hat{\beta_0}+\hat{\beta_1}X+\hat{\beta_2}D_2+\hat{\beta_3}D_3+\hat{\beta_4}D_2X+\hat{\beta_5}D_3X +\epsilon
\]

```{r}
mod2<-lm(Eggs ~ Weight * Genotype, data = mpi)
summary(mod2)
```

\[
\hat{Y}=12.80+1.61X+3.27D_2+1.4696D_3+-0.68D_2X+-0.36D_3X + \epsilon
\]


## B)

Using this model, report the three estimates of the slope for the regression lines.

- __Answer:__ The slope for genotype _ff_ is 1.96, the slope for genotype _fs_ is 1.28, and the slope for genotype _ss_ is 1.60.

## C)

Test the hypothesis that all three regression lines have the same slope. Write the null hypothesis, the p-value and a conclusion.

- __Answer:__ Let $\hat{\beta_1}$, $\hat{\beta_2}$, and $\hat{\beta_3}$ denote the regression coefficients slope of _ff_, _fs_, and _ss_ respectively. We want to test $H_0: \hat{\beta_1} = \hat{\beta_2} = \hat{\beta_3}$ vs. $H_A: H_0$ is false.

```{r}
anova(mod2)
```

We observe a p-value of 0.6886 so there is no evidence to reject the null hypothesis that there is no difference in slope between genotypes.

## D)

Now you are ready to answer the biological question formulated in problem 3. Use any/all of the results obtained before this question to conclude whether the Mpi genotypes differ in size-adjusted fecundity. Be brief but clearly explain your argument.

- __Answer:__ In the parallel lines model we did not observe evidence that the regression intercept varied by genotype (p-value > 0.1), and in the interaction model we did not observe evidence that the regression slopes varied by genotype (p-value > 0.1)