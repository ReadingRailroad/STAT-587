---
title: "Simonson Homework 9"
author: "Martin A. Simonson"
date: "April 5, 2019"
output: pdf_document
editor_options: 
  chunk_output_type: console
---

# 1. Multiple Linear Regression Formula

Consider a multiple linear regression model with n observations and m continuous predictor variables. Recall that multiple R2 = SSModel / (SSModel + SSError) and the overall F-ratio is F = MSModel/MSError. Use this to express F in terms of R2 (and m and n).

- __Answer:__ Let's start with algebra on the F-statistic:
\[
F = \frac{MS_{model}}{\hat{\sigma}^2} 
\]

Where 

\[
MS_{model} = \frac{SS_{model}}{DF_{model}} = \frac{SS_{model}}{m}
\]

and

$\hat{\sigma}^2 = MSE = \frac{SS_{error}}{DF_{within}} = \frac{SS_{error}}{(n-m-1)}$

therefore,

\[
F = \frac{\frac{SS_{model}}{m}}{\frac{{SS_{error}}{(n-m-1)}}} = \frac{SS_{model}}*{(n-m-1)}{SS_{error}*m}
\]

Now the $R^2$ is algebraicly converted as:

\[
\frac{1}{R^2} = \frac{SS_{model}+SS_{error}}{SS_{model}} = 1 + \frac{SS_{error}{SS_{model}}
\]

and consequently

\[
\frac{1}{R^2} - 1 = \frac{SS_{error}}{SS_{model}} = \frac{1-R^2}{R^2}
\]

And finally, we have a way to express $F$ in terms of $R^2$ and $n$ and $m$:

\[
F = \frac{R^2*(n-m-1)}{(1-R^2) * m}
\]


# 2. Drug Costs

Health plans use many tools to try to control the cost of prescription medicines. For older drugs, generic substitutes that are equivalent to name-brand drugs are sometimes available at a lower cost. Another tool that may lower costs is restricting the drugs that physicians may prescribe. For example, if three similar drugs are available for treating the same symptoms, a health plan may require physicians to prescribe only one of them. Since the usage of the chosen drug will be higher, the health plan may be able to negotiate a lower price for that drug.

The data in the file _drugcost.txt_, can be used to explore the effectiveness of these two strategies in controlling drug costs. The response variable is _COST_, the average cost of drugs per prescription per day, and predictors include GS (the extent to which the plan uses generic substitution, a number between zero, no substitution, and 100, always use a generic substitute if available) and RI (a measure of the restrictiveness of the plan, from zero, no restrictions on the physician, to 100, the maximum possible restrictiveness). Other variables that might impact cost were also collected, and are described in Table 1. The data are from the mid-1990s, and are for 29 plans throughout the United States with pharmacies
administered by a national insurance company.

The Drug Cost Data

```{r, echo = F}
df<-read.table("Data/drugcost.txt", header = T)

str(df)
```

## A. 

Fit a multiple linear regression model of COST on the other predictor variables. Report the overall F-ratio, p-value and the multiple R-squared.

```{r,echo=F}
fit<-lm(COST~RXPM+GS+RI+COPAY+AGE+F+MM,data = df)
summary(fit)
```

- __Answer:__ The overall F-statistic is 4.072 on 7 and 21 degrees of freedom, with a p-value of 0.00572. The multiple R-squared is 0.5758. 

## B.

Summarize your results with regard to the importance of _GS_ and _RI_. In particular, can we infer that more use of GS and RI will reduce drug costs?

- __Answer:__ The coefficient for _GS_ has a t-ratio of -4.018 associated with a p-value of 0.000622, providing very strong evidence that an increase in _GS_ will reduce drug costs. On the other hand, _RI_ has a low t-ratio of 0.160 associated with a p-value of 0.874468, providing no evidence that an increase in _RI_ will affect drug cost.

## C.

What are the other important variables and how do they affect the cost?

- __Answer:__ There is some evidence (p-value 0.054483) for an effect of _RXPM_; with an increase in _RXPM_ corresponding with an increase in drug cost. Also, there is evidence (p-value 0.020012) for an effect of _AGE_, with an increase in _AGE_ corresponding with a decrease in drug cost.

## D.

Find a 95% confidence interval for the coefficient of GS and interpret it in the given context.

```{r}

t.star<-2.08 # From t-table with 21 degrees of freedom
se<-2.830 * (10^-3) # SE of GS coefficient from summary output
est<- -1.137 * (10^-2) # GS coefficient estimate from summary output

lower<- est - t.star * se
upper<- est + t.star * se

data.frame(lower,upper)
```


- __Answer:__ We are 95% confident that, after accounting for the other variables, the coefficient for _GS_ lies between -0.0172564 and -0.0054836. In other words, with all other variables held constant a one unit increase in _GS_ would correspond with between 0.0172564 and 0.0054836 reduction in drug cost.

## E.

Run model diagnostics and comment

```{r,echo=F}
library(ggplot2)
library(gridExtra)
df$resid<-resid(fit)
df$fitted<-fitted(fit)
p1<-ggplot(df,aes(x=fitted,y=resid))+geom_point()+theme_classic()+geom_hline(yintercept = 0)
p2<-ggplot(df,aes(sample=resid))+stat_qq()+stat_qq_line()+theme_classic()
grid.arrange(p1,p2,ncol=2)
```

- __Answer:__ From both diagnostic plots we see that there may be an issue with the normality assumption (curvature of points at upper end of QQ plot) and that the homoskedasticity assumption is met due to a roughly even scatter of points on the residuals vs. fitted values plot.

# 3. Longnose Dace

The data in longnose_dace.txt gives the data on the abundance of longnose dace in streams in
Maryland. The columns are:

- stream : Name of the stream [ignore this column for fitting model]
- longnosedace : number of longnose in a 75m section of the stream.
- acreage : area (in acres) drained by the stream
- do2 : dissolved oxygen (in mg/litre)
- maxdepth : maximum depth (in cm) of the 75-meter segment of stream
- no3 : nitrate concentration (mg/liter)
- so4 : sulfate concentration (mg/liter)
- temp : water temperature on the sampling date (in oC).

```{r, include = F}
dace<-read.table("Data/longnose_dace.txt",header=T)
str(dace)
```

## A.

Use multiple linear model with the number of longnose dace as the response variable. Run a model diagnostics and check for model adequacy.

```{r, echo = F}
fit<-lm(longnosedace~acreage + do2 + maxdepth + no3 + so4 + temp, data = dace)
summary(fit)
dace$resid<-resid(fit)
dace$fitted<-fitted(fit)
p1<-ggplot(dace,aes(x=fitted,y=resid))+geom_point()+theme_classic()+geom_hline(yintercept = 0)
p2<-ggplot(dace,aes(sample=resid))+stat_qq()+stat_qq_line()+theme_classic()
grid.arrange(p1,p2,ncol=2)
```

- __Answer:__ The first longnose dace model had an F-statistic of 4.653 on 6 and 61 degrees of freedom, with an associated p-value of 0.0005905. However, the multiple R-squared value was 0.314, showing that the model only explains about 31% of overall variability. The diagnostic plots also show violations of homoskedascity and non-normal distributions.

## B.

Use an appropriate transformation [log] on the response, fit another MLR and run model diagnostics. Do things look better than A.? Irrespective of the answer, use the model in B. to answer all following questions.

```{r, echo = F}
fit<-lm(log(longnosedace)~acreage + do2 + maxdepth + no3 + so4 + temp, data = dace)
summary(fit)
dace$resid<-resid(fit)
dace$fitted<-fitted(fit)
p1<-ggplot(dace,aes(x=fitted,y=resid))+geom_point()+theme_classic()+geom_hline(yintercept = 0)
p2<-ggplot(dace,aes(sample=resid))+stat_qq()+stat_qq_line()+theme_classic()
grid.arrange(p1,p2,ncol=2)
```

- __Answer:__ Log-transformation of the response variable yielded diagnostic plots that show homoskedasticity and normality are met. 

## C.

Check for predictive power of each variable after accounting for the rest [That is, test each regression coefficient]. Report the table of estimates, s.e.'s, T-ratios and p-values. Write a short conclusion [1-2 sentences, include direction of an effect if present].

```{r}
summary(fit)
```

- __Answer:__ The variables that have strongest evidence for an additive effect are agreage, do2, maxdepth, no3, and temperature. Each variable has a positive relationship with the response, log(longnosedace).

## D.

Find a 95% confidence intervals for the coefficients of important predictor variables [i.e. the ones you found "significant" in C.].

```{r}
confint(fit)
```

- __Answer:__ The only variable in this model with a 95% confidence interval for its beta estimate that overlaps 0 is so4.

## E.

What are the units in the study? Is this an experimental sudy or observational?

- __Answer:__ The units of this \emph{observational} study are the number of longnose dace in a 75m section of stream.

## F.

Use your model to predict the median abundance of longnose dace and a 95% interval for the abundance in a Maryland river where the conditions are as follows:

- Acreage: 6298
- do2: 9.7 mg/l
- maxdepth: 65cm
- NO3: 7.5 mg/l
- SO4: 44 mg/l
- temperature: $20^\circ C$

```{r}
LD<-data.frame(predict(fit, 
        newdata = data.frame(acreage=6928,do2=9.7,maxdepth=65,no3=7.5,so4=44,temp=20),
        interval="predict"))
LD
```

- __Answer:__ The predicted median abundance of longnose dace for 75 m of stream with these characteristics is 5 (rounded to whole number for practicality: the true observed median would be a whole number: individual fish). We are 95% confident that the median abundance of longnose dace in a 75m reach of stream with these charcateristics would be between 2.28 and 7.14. 

# 4. Mammal Brain Weights

The data is given in _brainsize.txt_. Ignore book's questions and answer the following. Use a MLR of log(Brain) on log(Body), log(Gestation) and log(Litter) to answer the following questions:

## A.

Report the overall F-test and the p-value associated with it, multiple R-squared and the estimate of error variance (i.e. $\hat{\sigma}$).

```{r, include = F}
brain<-read.table("Data/brainsize.txt",header=T)
str(brain)
```

```{r}
fit<-lm(log(Brain)~log(Body)+log(Gestation)+log(Litter), data = brain)
summary(fit)
```

- __Answer:__ The F-statistic is 631.6 on 3 and 92 DF, with a p-value < 0.0001. $\hat{\sigma}$ is 0.4748 and the multiple $R^2$ is 0.9537.

## B.

Report the table of estimates for the coefficients. Which predictors seem to be important in predicting brain size?

- __Answer:__ [See summary table from A.] All three predictor variables have strong evidence for an additive effect on log-transformed brain size (p-values < 0.001).

## C.

Suppose we want to construct a 5% interval for the average brain size of red kangaroos. Should it be a confidence interval or prediction interval?

- __Answer:__ We would use a prediction interval because this estimate of the response is based on a single species rather than a group of species.

## D.

Obtain a 95% interval for C. Use the following information on red kangaroos:

- Average body weight: 63 lb. [\emph{warning: Use 28.5763 kg instead}]
- Average gestation period: 34 days
- Average litter size: 2

[Note: youll not be double penalized if you get C. wrong and if your answer in D. is consistent with C.]

```{r}
BS<-data.frame(predict(fit,
                       newdata=data.frame(Body=log(28.5763),Gestation=log(34),Litter=log(2)),
                       interval="predict"))
BS
```

- __Answer:__ We would expect the median brain weight to be 2.19 kg. We are 95% confident that the median brain weight for red kangaroos will be between 0.75 and 3.63 kg. 

## E.

Obtain the plot of residual-vs-fitted values. Point out a limitation of your model. [Hint: check the signs of the residuals associated with large body weights.]

```{r, echo=F}
brain$resid<-resid(fit)
brain$fitted<-fitted(fit)
p1<-ggplot(brain,aes(x=fitted,y=resid))+geom_point()+theme_classic()+geom_hline(yintercept = 0)
p2<-ggplot(brain,aes(sample=resid))+stat_qq()+stat_qq_line()+theme_classic()
grid.arrange(p1,p2,ncol=2)
```

- __Answer:__ In the residuals vs. fitted values plot there seem to be disproportionate distributions along zero, perhaps overdispersion is occurring. There is also a pattern of non-normal data for larger animals. These plots together suggest the model is not suitable for predicting brain weights in large animals.
